{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Code Model Asset Exchange Image Caption Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In a terminal window, run the following commands to set up the artifacts in yor local environment:\n",
    "```\n",
    "git clone https://github.com/IBM/MAX-Image-Caption-Generator\n",
    "cd MAX-Image-Caption-Generator\n",
    "curl -O http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/tf/im2txt/im2txt_ckpt.tar.gz\n",
    "tar -zxvf im2txt_ckpt.tar.gz -C assets/\n",
    "```    \n",
    "\n",
    "2. Copy this notebook into the `MAX-Image-Caption-Generator` directory.\n",
    "3. Run the notebook `jupyter notebook .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with Python version 3.6\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the latest package versions\n",
    "!pip install -Iv dask\n",
    "!pip install -Iv tensorflow\n",
    "!pip install -Iv tensorflowjs\n",
    "!pip install -Iv pandas\n",
    "# Restart the kernel after installation completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with dask 0.18, tensorflow 1.8, tensorflowjs 0.4.1, and pandas 0.23.1\n",
    "!pip show tensorflow tensorflowjs dask pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pprint\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('TF versions:', tf.GIT_VERSION, tf.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from checkpoint  and run a predicton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.backend import ModelWrapper\n",
    "\n",
    "# instantiate model\n",
    "m = ModelWrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to see list graph nodes/tensors\n",
    "\n",
    "#[n.name + '=>' +  n.op for n in m.sess.graph.as_graph_def().node]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to print a;; tensors in checkpoint file\n",
    "\n",
    "#from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "#chkp.print_tensors_in_checkpoint_file(checkpoint_dir_and_prefix, tensor_name='', all_tensors=True, all_tensor_names=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the test image and run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to an image file to run prediction\n",
    "test_image_path = './assets/plane.jpg'\n",
    "# display image\n",
    "Image(url=test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction on image\n",
    "with open(test_image_path, 'rb') as image:\n",
    "\n",
    "    pp.pprint(m.predict(image.read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "## Create a frozen model from the downloaded checkpoint\n",
    "\n",
    "- **[TensorFlow Model Files](https://www.tensorflow.org/extend/tool_developers/)**: developer's guide\n",
    "\n",
    "  - **checkpoints**: model format dependent on the code that created the model\n",
    "  ```\n",
    "    /\n",
    "    checkpoint\n",
    "    model.ckpt-?????.data-?????-of-?????\n",
    "    model.ckpt-?????.index\n",
    "    model.ckpt-?????.meta\n",
    "  ```\n",
    "  - **SavedModel**: model format independent of the code that created the model\n",
    "  ```\n",
    "    assets/\n",
    "    assets.extra/\n",
    "    variables/\n",
    "        variables.data-?????-of-?????\n",
    "        variables.index\n",
    "    saved_model.pb|saved_model.pbtxt\n",
    "  ```\n",
    "  - **frozen model**: single file graph def (variables converted into inline constants)\n",
    "  ```\n",
    "    model.pb\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the artifact output directory. Two sub-directories will be created in this location if they don't exist yet:\n",
    " * `frozen_graph_assets`\n",
    " * `web_assets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_graph_dir = \"{}/{}\".format(base_output_dir, \"frozen_graph_assets\")\n",
    "web_asset_dir = \"{}/{}\".format(base_output_dir, \"web_assets\")\n",
    "\n",
    "for dir in [frozen_graph_dir, web_asset_dir]: \n",
    "    try:\n",
    "     pathlib.Path(dir).mkdir(exist_ok=True)\n",
    "    except FileExistsError:\n",
    "     print(\"Output location {} already exists and is not a directory.\".format(dir))    \n",
    "    \n",
    "now = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "frozen_graph_filename = \"frozen_graph_{}.pb\".format(now)\n",
    "frozen_graph_stripped_filename = \"frozen_graph_stripped_{}.pb\".format(now)\n",
    "frozen_graph_path = \"{}/{}\".format(frozen_graph_dir, frozen_graph_filename)\n",
    "frozen_graph_stripped_path = \"{}/{}\".format(frozen_graph_dir, frozen_graph_stripped_filename)\n",
    "\n",
    "print('The frozen graph files for this model will be stored in `{}`'.format(frozen_graph_dir))\n",
    "print('The Tensorflow.js files for this model will be stored in `{}`'.format(web_asset_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create frozen graph from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from core.backend import ModelWrapper\n",
    "\n",
    "m = ModelWrapper()\n",
    "sess = m.sess\n",
    "\n",
    "input_graph_def = sess.graph.as_graph_def()\n",
    "\n",
    "\n",
    "# choose outputs wanted (most of the time you will only be choosing the prediction node)\n",
    "output_node_names = 'softmax,lstm/initial_state,lstm/state'\n",
    "\n",
    "\n",
    "# convert_variables_to_constants function in graph_util to pass the session, graph_def and the ends to save.\n",
    "output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess, # The session\n",
    "    input_graph_def, # input_graph_def is useful for retrieving the nodes \n",
    "    output_node_names.split(\",\")  \n",
    ")\n",
    "\n",
    "# serialize and write the output (frozen) graph to the file system\n",
    "\n",
    "with tf.gfile.GFile(frozen_graph_path, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "    print('Saved frozen graph: ' + frozen_graph_path)\n",
    " \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load frozen graph and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the frozen file and parse it to get the unserialized graph_def\n",
    "with tf.gfile.GFile(frozen_graph_path, \"rb\") as f:\n",
    "    restored_graph_def = tf.GraphDef()\n",
    "    restored_graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the graph_def using tf.import_graph_def function\n",
    "from core import inference_wrapper\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    tf.import_graph_def(\n",
    "        restored_graph_def,\n",
    "        input_map=None,\n",
    "        return_elements=None,\n",
    "        name=\"\"\n",
    "    )\n",
    "\n",
    "sess = tf.Session(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import logging\n",
    "from core.inference_utils import vocabulary\n",
    "from core.inference_utils import caption_generator\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# path to the word counts file (in repo)\n",
    "VOCAB_FILE = './assets/word_counts.txt'\n",
    "\n",
    "# run prediction\n",
    "def predict(sess, model, image_data):\n",
    "    # Create the vocabulary.\n",
    "    vocab = vocabulary.Vocabulary(VOCAB_FILE)\n",
    "\n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "    generator = caption_generator.CaptionGenerator(model, vocab)\n",
    "\n",
    "    captions = generator.beam_search(sess, image_data)\n",
    "\n",
    "    results = []\n",
    "    for i, caption in enumerate(captions):\n",
    "        # Ignore begin and end words.\n",
    "        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "        sentence = \" \".join(sentence)\n",
    "        # print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))\n",
    "        results.append((i, sentence, math.exp(caption.logprob)))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# helper function to get raw image data from given img path\n",
    "def get_image_data(path_to_img):\n",
    "    image_handle = open(path_to_img, 'rb')\n",
    "    raw_image_data = image_handle.read()\n",
    "    image_handle.close()\n",
    "    return raw_image_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display validation image and run prediction using the frozen graph. You can use any image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_path = './assets/soccer.jpg'\n",
    "# display image\n",
    "from IPython.display import Image\n",
    "Image(url=validation_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(validation_image_path, 'rb') as image:\n",
    "    # run prediction on image\n",
    "    res = predict(sess, model, image.read())\n",
    "    pp.pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Converting to a web-friendly format\n",
    "\n",
    "[https://github.com/tensorflow/tfjs-converter](https://github.com/tensorflow/tfjs-converter)\n",
    "\n",
    "\n",
    "```\n",
    "tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='softmax,lstm/initial_state,lstm/state' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    /path/to/frozen/model.pb \\\n",
    "    /path/to/web_asset_output_dir\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load frozen graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Frozen graph file: {}\".format(frozen_graph_path))\n",
    "print(\" File size: {} MiB\".format(os.path.getsize(frozen_graph_path) >> 20))\n",
    "\n",
    "# load the frozen file and parse it to get the unserialized graph_def\n",
    "with tf.gfile.GFile(frozen_graph_path, \"rb\") as f:\n",
    "    restored_graph_def = tf.GraphDef()\n",
    "    restored_graph_def.ParseFromString(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip unused nodes from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# TODO figure out the appropriate input and output nodes required\n",
    "# input_node_names = ['Mul']\n",
    "# output_node_names = ['softmax', 'lstm/initial_state', 'lstm/state']\n",
    "input_node_names = []\n",
    "output_node_names = ['softmax']\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = restored_graph_def,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "\n",
    "with gfile.GFile(frozen_graph_stripped_path, \"wb\") as f:\n",
    "    f.write(gdef.SerializeToString())\n",
    "    print(\"Stripped frozen graph file: {}\".format(frozen_graph_stripped_path))\n",
    "    print(\" File size: {} MiB\".format(os.path.getsize(frozen_graph_stripped_path) >> 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert frozen graph to TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate frozen model path and desired output path for web format\n",
    "\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='softmax' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    {frozen_graph_stripped_path} \\\n",
    "    {web_asset_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Web asset directory {}:\".format(web_asset_dir))\n",
    "web_assets = os.listdir(web_asset_dir)\n",
    "web_assets.sort()\n",
    "for file in web_assets:\n",
    "    file_stat = os.stat(\"{}/{}\".format(web_asset_dir,file))\n",
    "    print(\" {} {} {:>20}\".format(file.ljust(30), time.ctime(file_stat.st_mtime), file_stat.st_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the artifacts listed above in your Tensorflow.js application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
